\documentclass{article}


\usepackage{arxiv}

\usepackage[utf8]{inputenc} % allow utf-8 input
\usepackage[T1]{fontenc}    % use 8-bit T1 fonts
\usepackage{hyperref}       % hyperlinks
\usepackage{url}            % simple URL typesetting
\usepackage{booktabs}       % professional-quality tables
\usepackage{amsfonts}       % blackboard math symbols
\usepackage{nicefrac}       % compact symbols for 1/2, etc.
\usepackage{microtype}      % microtypography
\usepackage{lipsum}
\usepackage{amsthm}
\usepackage{amsmath}
\usepackage{eucal}
\usepackage{mathtools}
\usepackage[table]{xcolor}
\usepackage{stmaryrd}
\usepackage{amsfonts}
\usepackage{lstlistings-golang}
\usepackage{caption}

% Code with syntax highlighting
\usepackage{fancyvrb}
\usepackage{listingsutf8}
\usepackage{textcomp}
\usepackage{placeins}


\theoremstyle{plain}% default
\newtheorem{thm}{Theorem}[section]
\newtheorem{lem}[thm]{Lemma}
\newtheorem{prop}[thm]{Proposition}
\newtheorem*{cor}{Corollary}
\theoremstyle{definition}
\newtheorem{defn}{Definition}[section]
\newtheorem{conj}{Conjecture}[section]
\newtheorem{exmp}{Example}[section]
\newtheorem{exrc}[exmp]{Exercise}
\theoremstyle{remark}
\newtheorem*{comm}{Comment}
\newtheorem*{note}{Note}
\newtheorem{case}{Case}

\def\C{\mathbb{C}}
\def\N{\mathbb{N}}
\def\Q{\mathbb{Q}}
\def\R{\mathbb{R}}
\def\Z{\mathbb{Z}}
\def\K{\mathbb{K}}

\DeclarePairedDelimiter\sqmap{\llbracket}{\rrbracket}
\DeclarePairedDelimiter\spanset{\langle}{\rangle}


\newcommand{\diag}[1]{\text{diag}\left(#1\right)}
\newcommand{\mspan}[1]{\text{span}\left(#1\right)}
\newcommand{\dom}{\text{dom}}
\newcommand{\mker}[1]{\text{ker}\left(#1\right)}
\newcommand{\mrank}[1]{\text{rank}\left(#1\right)}
\newcommand{\llwb}{\approx_{\mathcal{L}}}
\newcommand{\langlwa}[2]{\sqmap{#1}^\mathcal{L}_{#2}}

% matrix commands
\newcommand{\vvec}[2]{
	\begin{pmatrix}
		#1 \\ #2
	\end{pmatrix}
}
\newcommand{\vvvec}[3]{
	\begin{pmatrix}
		#1 \\ #2 \\ #3
	\end{pmatrix}
}
\newcommand{\vvvvec}[4]{
	\begin{pmatrix}
		#1 \\ #2 \\ #3 \\ #4
	\end{pmatrix}
}

% Code Listings
\definecolor{vgreen}{RGB}{104,180,104}
\definecolor{vblue}{RGB}{49,49,255}
\definecolor{vorange}{RGB}{255,143,102}
\lstset{
  numbers=left,
  frame=tb,
  commentstyle=\color{mygreen},
	basicstyle=\ttfamily,
	columns=fullflexible,
  keepspaces=false,
  showstringspaces=false,
  extendedchars=true,
  mathescape=true,
  breaklines, breakatwhitespace=true
}

\title{DRAFT: Go Implementation of Up-To Techniques for Equivalence of Weighted Languages}

%\thanks{Use footnote for providing further
%information about author (webpage, alternative
%address)---\emph{not} for acknowledging funding agencies.}

\author{
  Alessandro Cheli \\
  Undergraduate Student \\
  Department of Computer Science \\
  Università di Pisa\\
  Pisa, PI 56127 \\
  \texttt{a.cheli6@studenti.unipi.it} \\
  %% examples of more authors
  %% \And
  %% Elias D.~Striatum \\
  %% Department of Electrical Engineering\\
  %% Mount-Sheikh University\\
  %% Santa Narimana, Levand \\
  %% \texttt{stariate@ee.mount-sheikh.edu} \\
}

\definecolor{mygreen}{rgb}{0,0.6,0}



\begin{document}
\maketitle

\begin{abstract}
Weighted automata generalize non-deterministic automata by adding
a quantity expressing the weight (or probability) of the execution of each transition.
In this work we propose an implementation of two algorithms for computing language 
equivalence in finite state weighted automata (WAs). The first, a
linear partition refinement algorithm, computes the largest linear weighted bisimulation
for any given LWA (Linear Weighted Automaton) through an iterative method, 
the second algorithm checks the language equivalence 
of two vectors (states) for a given weighted automata by using an additional
data structure representing a congruence relation.
We then compare results of the two algorithms to verify their correctness
and performance on randomly generated samples. 
We finally provide comparison of runtime statistics and suggest 
which of the two algorithm is the best choice for different usage cases.
\end{abstract}


% keywords can be removed
\keywords{First keyword \and Second keyword \and More}


\input{sections/introduction.tex}

\input{sections/notation.tex}

%=========================================================================


\input{sections/algorithms.tex}




\section{Implementation}
\label{sec:impl}

The algorithms and data structures for this paper are implemented in the Go programming 
language. This implementation makes use of the Gonum library for numerical 
computations. We only import the Gonum libraries for matrices and linear algebra 
and visual plotting of samples and functions.
Real numbers are implemented with double precision floating point numbers,  
known as the \texttt{float64} type in the Go programming language.


\begin{defn}
  \textbf{Applications of SVD} \\

  Let's consider the singular value decomposition of a matrix $A \in \R^{m \times n}$:

  \begin{equation*}
    \begin{aligned}
      A = U \Sigma V^T & \quad & \Sigma = \diag{\sigma_1, \sigma_2, \hdots, \sigma_r  } 
       & \quad &  U \in \R^{m \times m} & \quad & V \in \R^{n \times n}
    \end{aligned}
  \end{equation*}

  Where $V$ and $U$ are orthogonal and the singular values are ordered: $\sigma_1 \geq \sigma_2 \geq \hdots \geq \sigma_r \geq 0$.
  It follows that $\mrank{A}$ is equal to the number of nonzero singular values, and
  as explained in \cite{svd}:
  
  \begin{enumerate}
    \item  $\mrank{A} = \mrank{\Sigma} = r$
    \item The column space of $A$ is spanned by the first $r$ columns of $U$.
    \item The null space of $A$ is spanned by the last $n − r$ columns of $V$.
    \item The row space of $A$ is spanned by the first $r$ columns of $V$.
    \item The null space of $A^T$ is spanned by the last $m − r$ columns of $U$.
  \end{enumerate}
  
  Of our interest, are only the computation of the null space and columns space.
  The implementation, applying SVD, 
  can be found in files \texttt{lin/colspace.go} and \texttt{lin/nullspace.go}.
\end{defn}






\subsection{Implementing the backwards partition refinement algorithm}

To compute $\llwb$ at the last step of the algorithm,
we need to compute $R_j^0$.
If $V$ is a vector space and $W$ is a
subspace of $W$, the annihilator of $W$, respectively $W^0$ is 
a subspace of the space $V^*$ of linear functionals on $V$.
$W^0$ are the functionals that annihilate on $W$. Since 
we are working on subspaces of $\R^n$, we can directly compute 
the orthogonal complement in our implementation instead of the
annihilator.


\begin{prop}
  If $V$ is a finite dimensional vector space defined with an inner product
  $\langle \cdot , \cdot \rangle$ and $W$ is a subspace of $V$
  then the image of the annhilitaor $W^0$ through the linear 
  isomorphism $\varphi: V^* \to V$ induced by the inner product, 
  is the orthogonal of $W$ with respect to the said inner product.
\end{prop}

\begin{proof}
  Let $V$ be an inner product space over the field $\K$ with an inner product defined as
  $\langle \cdot , \cdot \rangle : V \times V \to \K$. 
  Every linear functional can be 
  represented with a vector. Let $\xi : V \to \K$ be a functional, 
  $\xi \in  W^0$. Because $\xi(w)=0 \quad \forall  w \in W$, 
  if $v$ represents $\xi$ we have that $(v, w)=\xi(w)=0$ for all $w \in W$. 
  We obtain that $\varphi(W^0) \subseteq W^{\perp}$.
  If $v \in W^\perp$  
  then the functional $x \mapsto (v, x)$ cancels over $W$ 
  (by the definition of orthogonality).
\end{proof}


To compute the orthogonal complement of a vector subspace $W$, we
compute $W^\perp = \mker{A^T}$, where $A$ is the matrix with 
column vectors in the spanning set of $W$ as its columns. Precisely, $W$ is 
represented as the 
column space of $A$. Proof is available in \cite{ila}.


%=============================================================


%\begin{figure}
%  \centering
%  \fbox{\rule[-.5cm]{4cm}{4cm} \rule[-.5cm]{4cm}{0cm}}
%  \caption{Sample figure caption.}
%  \label{fig:fig1}
%\end{figure}


%\begin{table}
% \caption{Sample table title}
%  \centering
%  \begin{tabular}{lll}
%    \toprule
%    \multicolumn{2}{c}{Part}                   \\
%    \cmidrule(r){1-2}
%    Name     & Description     & Size ($\mu$m) \\
%    \midrule
%    Dendrite & Input terminal  & $\sim$100     \\
%    Axon     & Output terminal & $\sim$10      \\
%    Soma     & Cell body       & up to $10^6$  \\
%    \bottomrule
%  \end{tabular}
%  \label{tab:table}
%\end{table}





\bibliographystyle{unsrt}
\bibliography{references}  %%% Remove comment to use the external .bib file (using bibtex).
%%% and comment out the ``thebibliography'' section.

% 
% %%% Comment out this section when you \bibliography{references} is enabled.
% \begin{thebibliography}{1}
% 
% \bibitem{kour2014real}
% George Kour and Raid Saabne.
% \newblock Real-time segmentation of on-line handwritten arabic script.
% \newblock In {\em Frontiers in Handwriting Recognition (ICFHR), 2014 14th
%   International Conference on}, pages 417--422. IEEE, 2014.
% 
% \bibitem{kour2014fast}
% George Kour and Raid Saabne.
% \newblock Fast classification of handwritten on-line arabic characters.
% \newblock In {\em Soft Computing and Pattern Recognition (SoCPaR), 2014 6th
%   International Conference of}, pages 312--318. IEEE, 2014.
% 
% \bibitem{hadash2018estimate}
% Guy Hadash, Einat Kermany, Boaz Carmeli, Ofer Lavi, George Kour, and Alon
%   Jacovi.
% \newblock Estimate and replace: A novel approach to integrating deep neural
%   networks with existing applications.
% \newblock {\em arXiv preprint arXiv:1804.09028}, 2018.
% 
% \end{thebibliography}
% 
% 
\appendix

%\input{sections/appendix.tex}
\end{document}
 